# KOSMES (중소벤처기업진흥공단) Enhanced Scraper 개발 인사이트

## 사이트 특성 분석

### 1. 기본 정보
- **사이트**: KOSMES (중소벤처기업진흥공단)
- **URL**: https://www.kosmes.or.kr/nsh/SH/NTS/SHNTS001M0.do
- **사이트 코드**: kosmes
- **인코딩**: UTF-8
- **SSL**: HTTPS (유효한 인증서)

### 2. 사이트 구조 특징
- **동적 컨텐츠**: JavaScript 기반 동적 로딩 (Playwright 필수)
- **테이블 구조**: 표준 HTML 테이블 (번호, 구분, 제목, 등록일)
- **페이지네이션**: JavaScript `goPage(pageNum)` 함수 사용
- **상세페이지**: 동적 컨텐츠 로딩 (`TTU_TXT` div, `downFile1/2/3` div)

### 3. 첨부파일 다운로드 특성
- **JavaScript 함수**: `lfn_fileDown('fileMskTxt', 'fileName', 'upload')`
- **다운로드 URL**: `/nsh/cmm/fms/FileDown.do?fileMskTxt={fileMskTxt}&fileName={fileName}`
- **파일 타입**: PDF, HWP, HWPX, JPG, PNG, DOCX, ZIP
- **한글 파일명**: 100% 한글 파일명 지원

## 기술적 구현 특징

### 1. Playwright 사용 필요성
```python
def fetch_page_with_playwright(self, url: str, page_num: int = 1) -> str:
    """Playwright를 사용하여 동적 페이지 로딩"""
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        
        # 네트워크 대기 및 동적 컨텐츠 로딩
        page.goto(url, wait_until="networkidle")
        
        if 'SHNTS001F0.do' in url:  # 상세페이지
            page.wait_for_selector('#TTU_TXT, #downFile1', timeout=10000)
            time.sleep(3)  # JavaScript 실행 완료 대기
```

**이유**: KOSMES 사이트는 공고 목록과 상세 내용을 JavaScript로 동적 로딩하므로 일반 requests로는 빈 테이블만 반환됨.

### 2. 동적 컨텐츠 파싱
```python
def _parse_detail_fallback(self, html_content: str, announcement_url: str) -> Dict[str, Any]:
    """KOSMES 특화된 상세 페이지 파싱"""
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # 본문은 TTU_TXT ID를 가진 div에서 추출
    content_div = soup.find('div', id='TTU_TXT')
    if content_div:
        content = content_div.get_text(separator='\n', strip=True)
    
    # 첨부파일은 downFile1, downFile2, downFile3 div에서 추출
    for i in range(1, 4):
        div_id = f'downFile{i}'
        download_div = soup.find('div', id=div_id)
        if download_div and download_div.get('style') != 'display: none;':
            # lfn_fileDown 함수에서 파라미터 추출
```

### 3. 첨부파일 다운로드 URL 구성
```python
# KOSMES 특화 패턴
params_match = re.search(r"lfn_fileDown\s*\(\s*['\"]([^'\"]*)['\"],\s*['\"]([^'\"]*)['\"],\s*['\"]([^'\"]*)['\"]", onclick)
if params_match:
    file_msk_txt, file_name, upload_type = params_match.groups()
    download_url = f"{self.base_url}/nsh/cmm/fms/FileDown.do?fileMskTxt={file_msk_txt}&fileName={file_name}"
```

## 주요 해결책

### 1. JavaScript 렌더링 대응
**문제**: 일반 HTTP 요청으로는 동적 컨텐츠 접근 불가
**해결**: Playwright 사용하여 브라우저 환경에서 JavaScript 실행 후 HTML 추출

### 2. 페이지네이션 처리
**문제**: JavaScript `goPage()` 함수 기반 페이지 이동
**해결**: 모든 페이지에 동일한 기본 URL 사용, Playwright에서 JavaScript 함수 호출

### 3. 동적 첨부파일 로딩
**문제**: 첨부파일이 JavaScript로 동적 생성
**해결**: 충분한 대기시간(3초) 후 DOM에서 `downFile1/2/3` div 추출

### 4. 한글 파일명 처리
**특징**: KOSMES는 UTF-8 인코딩으로 한글 파일명이 정상 처리됨
```python
# 별도 인코딩 처리 불필요 (UTF-8 기본)
filename = file_name or filename
```

## 테스트 결과

### 1페이지 테스트 (10개 공고):
- **성공률**: 100% (10/10)
- **첨부파일**: 17개 (100% 한글 파일명)
- **실행시간**: 약 61초
- **파일 형식**: PDF, HWP, HWPX, JPG, PNG, DOCX, ZIP

### 3페이지 테스트 (19개 공고, 타임아웃):
- **처리된 공고**: 18개
- **첨부파일**: 34개
- **성능 이슈**: Playwright 사용으로 인한 속도 저하

## 재사용 가능한 패턴

### 1. Playwright 기반 동적 사이트 처리
```python
class EnhancedKosmesScraper(StandardTableScraper):
    def __init__(self):
        super().__init__()
        self.requires_javascript = True  # Playwright 사용 플래그
    
    def _get_page_announcements(self, page_num: int) -> List[Dict[str, Any]]:
        if self.requires_javascript:
            html_content = self.fetch_page_with_playwright(page_url, page_num)
            return self.parse_list_page(html_content)
```

### 2. 동적 컨텐츠 대기 패턴
```python
# 상세페이지 vs 목록페이지 구분 대기
if 'SHNTS001F0.do' in url:  # 상세페이지
    page.wait_for_selector('#TTU_TXT, #downFile1', timeout=10000)
    time.sleep(3)  # JavaScript 실행 완료 대기
else:  # 목록페이지
    page.wait_for_selector('table tbody tr', timeout=10000)
```

### 3. JavaScript 함수 파라미터 추출 패턴
```python
# 정규표현식으로 JavaScript 함수 파라미터 추출
params_match = re.search(r"lfn_fileDown\s*\(\s*['\"]([^'\"]*)['\"],\s*['\"]([^'\"]*)['\"],\s*['\"]([^'\"]*)['\"]", onclick)
```

## 특별한 기술적 도전과 해결책

### 1. 성능 최적화 vs 안정성
**도전**: Playwright 사용으로 인한 속도 저하 (페이지당 3-6초)
**해결**: 
- 네트워크 대기(`networkidle`) 사용
- 선택적 JavaScript 실행 대기
- 브라우저 재사용 고려 (현재는 페이지별 새 브라우저)

### 2. 메모리 효율성
**도전**: 각 페이지마다 브라우저 인스턴스 생성
**해결**: 
- 현재: 페이지별 브라우저 생성/종료
- 개선안: 세션 레벨 브라우저 재사용 가능

### 3. 동적 컨텐츠 타이밍
**도전**: JavaScript 실행 완료 시점 예측 어려움
**해결**: 
- `wait_for_selector` 사용으로 특정 요소 대기
- 추가 고정 대기시간(3초) 적용
- 에러 핸들링으로 타임아웃 대응

## Enhanced 스크래퍼 아키텍처 장점

1. **StandardTableScraper 상속**: 공통 기능 재사용
2. **Playwright 통합**: JavaScript 렌더링 자동 처리
3. **중복 검사**: 해시 기반 제목 중복 감지
4. **향상된 로깅**: 구조화된 진행상황 추적
5. **한글 파일명**: 다단계 인코딩 처리 (KOSMES는 UTF-8로 문제없음)

## 적용 가능 사이트 유형

이 패턴은 다음과 같은 사이트에 적용 가능:
- JavaScript 기반 동적 컨텐츠 로딩
- AJAX/JSON API 기반 페이지네이션
- React/Vue 등 SPA 기반 정부기관 사이트
- 첨부파일이 JavaScript로 동적 생성되는 사이트

## 성능 벤치마크

- **목록 페이지 로딩**: 3-4초 (Playwright)
- **상세 페이지 로딩**: 6-7초 (JavaScript 대기 포함)
- **첨부파일 다운로드**: 1-2초 (각 파일)
- **전체 처리 속도**: 페이지당 약 60-90초 (10개 공고 기준)

이는 일반 HTTP 요청 기반 스크래퍼(페이지당 10-20초)보다 느리지만, 
동적 컨텐츠 접근이 필수인 사이트에서는 유일한 해결책임.