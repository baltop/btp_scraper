#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YWBIC (ì˜ì›”êµ° ë¹„ì¦ˆë‹ˆìŠ¤ ì¸íë² ì´í„° ì„¼í„°) Enhanced Scraper í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import logging
from datetime import datetime
from enhanced_ywbic_scraper import EnhancedYwbicScraper

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(f'ywbic_test_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)

def test_ywbic_scraper(pages=3):
    """YWBIC ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸"""
    print(f"ğŸš€ YWBIC Enhanced Scraper í…ŒìŠ¤íŠ¸ ì‹œì‘ (ìµœëŒ€ {pages}í˜ì´ì§€)")
    print("=" * 60)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    output_dir = "output/ywbic"
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
        scraper = EnhancedYwbicScraper()
        print(f"âœ… ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
        start_time = datetime.now()
        scraper.scrape_pages(max_pages=pages, output_base=output_dir)
        end_time = datetime.now()
        
        duration = end_time - start_time
        print(f"â±ï¸  ìŠ¤í¬ë˜í•‘ ì†Œìš” ì‹œê°„: {duration}")
        
        # ê²°ê³¼ ê²€ì¦
        verify_results(output_dir, pages)
        
    except Exception as e:
        logger.error(f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        raise

def verify_results(output_dir, expected_pages):
    """ê²°ê³¼ ê²€ì¦"""
    print("\nğŸ“Š ê²°ê³¼ ê²€ì¦ ì¤‘...")
    print("-" * 40)
    
    if not os.path.exists(output_dir):
        print("âŒ ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        return
    
    # 1. ê³µê³  ë””ë ‰í† ë¦¬ ìˆ˜ í™•ì¸
    announcement_dirs = [d for d in os.listdir(output_dir) 
                        if os.path.isdir(os.path.join(output_dir, d))]
    
    total_announcements = len(announcement_dirs)
    expected_announcements = expected_pages * 25  # í˜ì´ì§€ë‹¹ ì•½ 25ê°œ (ê³µì§€ + ì¼ë°˜)
    
    print(f"ğŸ“ ìˆ˜ì§‘ëœ ê³µê³  ìˆ˜: {total_announcements}ê°œ")
    print(f"ğŸ“„ ì˜ˆìƒ ê³µê³  ìˆ˜: ì•½ {expected_announcements}ê°œ")
    
    if total_announcements > 0:
        success_rate = min(100, (total_announcements / expected_announcements) * 100)
        print(f"âœ… ìˆ˜ì§‘ ì„±ê³µë¥ : {success_rate:.1f}%")
    else:
        print("âŒ ìˆ˜ì§‘ëœ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤")
        return
    
    # 2. ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ìƒíƒœ í™•ì¸
    total_files = 0
    total_size = 0
    korean_files = 0
    
    for announcement_dir in announcement_dirs:
        dir_path = os.path.join(output_dir, announcement_dir)
        if os.path.isdir(dir_path):
            files = [f for f in os.listdir(dir_path) 
                    if os.path.isfile(os.path.join(dir_path, f)) and f != 'content.md']
            
            total_files += len(files)
            
            for file in files:
                file_path = os.path.join(dir_path, file)
                file_size = os.path.getsize(file_path)
                total_size += file_size
                
                # í•œê¸€ íŒŒì¼ëª… í™•ì¸
                if any(ord(char) > 127 for char in file):
                    korean_files += 1
    
    print(f"ğŸ“ ë‹¤ìš´ë¡œë“œëœ ì²¨ë¶€íŒŒì¼: {total_files}ê°œ")
    print(f"ğŸ’¾ ì´ íŒŒì¼ í¬ê¸°: {format_size(total_size)}")
    print(f"ğŸ‡°ğŸ‡· í•œê¸€ íŒŒì¼ëª…: {korean_files}ê°œ")
    
    # 3. ìƒ˜í”Œ ê³µê³  ë‚´ìš© í™•ì¸
    print("\nğŸ“‹ ìƒ˜í”Œ ê³µê³  í™•ì¸:")
    print("-" * 30)
    
    sample_count = min(3, len(announcement_dirs))
    for i, announcement_dir in enumerate(announcement_dirs[:sample_count]):
        dir_path = os.path.join(output_dir, announcement_dir)
        content_file = os.path.join(dir_path, 'content.md')
        
        if os.path.exists(content_file):
            with open(content_file, 'r', encoding='utf-8') as f:
                content = f.read()
                title_line = content.split('\n')[0] if content else "ì œëª© ì—†ìŒ"
                print(f"{i+1}. {title_line}")
        else:
            print(f"{i+1}. {announcement_dir} - content.md ì—†ìŒ")
    
    # 4. ì›ë³¸ URL í¬í•¨ í™•ì¸
    url_included = 0
    for announcement_dir in announcement_dirs[:5]:  # ì²˜ìŒ 5ê°œë§Œ í™•ì¸
        dir_path = os.path.join(output_dir, announcement_dir)
        content_file = os.path.join(dir_path, 'content.md')
        
        if os.path.exists(content_file):
            with open(content_file, 'r', encoding='utf-8') as f:
                content = f.read()
                if 'ywbic.kr' in content:
                    url_included += 1
    
    print(f"ğŸ”— ì›ë³¸ URL í¬í•¨: {url_included}/5ê°œ í™•ì¸")
    
    print("\nâœ… ê²€ì¦ ì™„ë£Œ!")

def format_size(size_bytes):
    """íŒŒì¼ í¬ê¸°ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='YWBIC Enhanced Scraper í…ŒìŠ¤íŠ¸')
    parser.add_argument('--pages', type=int, default=3, help='ìŠ¤í¬ë˜í•‘í•  í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ê°’: 3)')
    parser.add_argument('--single', action='store_true', help='1í˜ì´ì§€ë§Œ í…ŒìŠ¤íŠ¸')
    
    args = parser.parse_args()
    
    pages = 1 if args.single else args.pages
    
    try:
        test_ywbic_scraper(pages)
        print(f"\nğŸ‰ YWBIC ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    except Exception as e:
        print(f"\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()