#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Export Voucher File2List API í…ŒìŠ¤íŠ¸
ì‹¤ì œ íŒŒì¼ ëª©ë¡ê³¼ í˜„ì¬ sec_codeë¥¼ ê°€ì ¸ì˜¤ê¸°
"""

import requests
import json
from enhanced_export_voucher_scraper import EnhancedExportVoucherScraper

def test_file2list_api():
    """File2List API í…ŒìŠ¤íŠ¸"""
    print("Export Voucher File2List API í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    scraper = EnhancedExportVoucherScraper()
    scraper._initialize_session()
    
    # ì²« ë²ˆì§¸ ê³µê³ ì˜ DOC ID
    doc_id = "DOC_000000002529310"
    
    # File2List API í˜¸ì¶œ
    api_url = "https://www.exportvoucher.com/common/File2List"
    
    try:
        print(f"ğŸ” API í˜¸ì¶œ: {api_url}")
        print(f"ğŸ“‹ DOC ID: {doc_id}")
        
        # GET ìš”ì²­ìœ¼ë¡œ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        response = scraper.session.get(
            api_url,
            params={'docId': doc_id},
            verify=scraper.verify_ssl,
            timeout=10
        )
        
        print(f"ğŸ“¡ ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        print(f"ğŸ“„ ì‘ë‹µ ê¸¸ì´: {len(response.text)} bytes")
        
        if response.status_code == 200:
            try:
                # JSON íŒŒì‹± ì‹œë„
                file_data = response.json()
                print(f"âœ… JSON íŒŒì‹± ì„±ê³µ: {len(file_data)}ê°œ íŒŒì¼")
                
                for i, file_info in enumerate(file_data, 1):
                    print(f"\nğŸ“ íŒŒì¼ {i}:")
                    print(f"  - íŒŒì¼ëª…: {file_info.get('fileName', 'N/A')}")
                    print(f"  - íŒŒì¼ID: {file_info.get('fileId', 'N/A')}")
                    print(f"  - sec_code: {file_info.get('secCode', 'N/A')}")
                    print(f"  - íŒŒì¼ í¬ê¸°: {file_info.get('fileSize', 'N/A')}")
                    
                    # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ URL ìƒì„±
                    if 'fileId' in file_info and 'secCode' in file_info:
                        download_url = f"https://www.exportvoucher.com/common.FileDownload.do?file_id={file_info['fileId']}&sec_code={file_info['secCode']}"
                        print(f"  - ë‹¤ìš´ë¡œë“œ URL: {download_url}")
                        
                        # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸
                        print(f"  ğŸ”„ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸ ì¤‘...")
                        test_response = scraper.session.get(download_url, verify=scraper.verify_ssl, timeout=30)
                        print(f"     ìƒíƒœ: {test_response.status_code}")
                        print(f"     í¬ê¸°: {len(test_response.content)} bytes")
                        print(f"     Content-Type: {test_response.headers.get('content-type', 'N/A')}")
                        print(f"     Content-Disposition: {test_response.headers.get('content-disposition', 'N/A')}")
                
                return file_data
                
            except json.JSONDecodeError:
                print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨ - í…ìŠ¤íŠ¸ ì‘ë‹µ:")
                print(response.text[:500])
                
        else:
            print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: HTTP {response.status_code}")
            print(f"ì‘ë‹µ: {response.text[:200]}")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    return None

if __name__ == "__main__":
    result = test_file2list_api()
    if result:
        print(f"\nğŸ‰ ì„±ê³µ! {len(result)}ê°œ íŒŒì¼ ì •ë³´ íšë“")
    else:
        print("\nğŸ’¡ ë‹¤ë¥¸ ë°©ë²• í•„ìš”")