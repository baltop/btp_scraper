# 한국산업안전보건공단(KOSHA) Enhanced 스크래퍼 개발 인사이트

## 1. 사이트 기본 정보
- **사이트**: 한국산업안전보건공단(KOSHA) 공고문
- **URL**: https://www.kosha.or.kr/kosha/report/notice.do
- **구조**: 표준 HTML 테이블 기반 게시판
- **페이지네이션**: GET 파라미터 방식 (article.offset)
- **SSL**: 정상 지원 (verify=True)
- **인코딩**: UTF-8

## 2. 기술적 특성 및 구현 해법

### 2.1 목록 페이지 구조
```html
<table class="Board-list-type01">
  <thead>번호, 제목, 작성자, 등록일, 첨부, 조회</thead>
  <tbody>
    <tr>
      <td class="board-list-uid">번호</td>
      <td class="board-list-title"><a href="?mode=view&articleNo=455898...">제목</a></td>
      <td class="board-list-writer">작성자</td>
      <td class="board-list-date">날짜</td>
      <td class="board-list-file">첨부파일 표시</td>
      <td class="board-list-view">조회수</td>
    </tr>
  </tbody>
</table>
```

**핵심 해결책**: 
- 테이블 선택자: `table.Board-list-type01`
- 제목 셀 클래스: `board-list-title` 확인 필수
- **상대 URL 처리**: `href="?mode=view..."` → `list_url + href`

### 2.2 페이지네이션 패턴
- **1페이지**: `?mode=list&articleLimit=10&article.offset=0` (기본)
- **N페이지**: `?mode=list&articleLimit=10&article.offset={(N-1)*10}`
- **페이지당**: 10개 공고

### 2.3 상세 페이지 구조
```html
<table summary="게시판 상세 페이지입니다.">
  <tr class="view-body">
    <td class="p17">본문 내용</td>
  </tr>
</table>
```

**본문 추출**:
- 주 선택자: `tr.view-body td.p17`
- 대체 선택자: `table[summary*="상세"] .view-body .p17`

### 2.4 첨부파일 구조
```html
<td class="view-down">
  <a href="javascript:viewdown(1)">첨부파일(1)</a>
  <div class="view-downbox">
    <a href="?mode=download&articleNo=455898&attachNo=262723">
      [붙임] 파일명.hwp
    </a>
  </div>
</td>
```

**첨부파일 추출**:
- JavaScript 토글: `viewdown(1)` - 무시
- 실제 다운로드: `?mode=download&articleNo=...&attachNo=...`
- **URL 처리**: 상대 경로를 `list_url + href`로 구성

## 3. 핵심 기술적 도전과 해결책

### 3.1 상대 URL 처리 문제
**문제**: href="?mode=view&articleNo=..." 형태의 상대 경로
**해결**: 조건부 URL 구성
```python
if href.startswith('?'):
    detail_url = f"{self.list_url}{href}"
else:
    detail_url = urljoin(self.base_url, href)
```

### 3.2 한글 파일명 처리
**성공률**: 100% (34개 파일 모두 한글명 정상 처리)
**방법**: Enhanced 베이스 스크래퍼의 다단계 인코딩 복구 시스템 활용
- RFC 5987 형식 우선 처리
- UTF-8, EUC-KR, CP949 순차 시도
- Content-Disposition 헤더 분석

### 3.3 테이블 행 필터링
**문제**: 헤더 행과 데이터 행 구분
**해결**: 
```python
if not title_cell.get('class') or 'board-list-title' not in title_cell.get('class', []):
    continue  # 제목 셀이 아닌 행 스킵
```

## 4. 실제 테스트 결과

### 4.1 성능 지표
- **총 공고 수**: 34개 (3페이지)
- **성공률**: 100%
- **첨부파일**: 34개 (122MB)
- **한글 파일명**: 100% 정상 처리
- **원본 URL 포함**: 100%

### 4.2 파일 형식 분포
- **HWP**: 한글 문서 (공고문, 안내문)
- **PDF**: 공고서, 안내서, 결과보고서
- **ZIP**: 복합 첨부파일 (양식, 서류 일체)
- **XLSX**: 명단, 결과 데이터

### 4.3 대용량 파일 처리
- 최대 파일: 79MB (장마철 안전보건 길잡이 PDF)
- 스트리밍 다운로드 정상 작동
- 평균 파일 크기: 3.6MB

## 5. Enhanced 스크래퍼 패턴 적용

### 5.1 표준 구현 패턴
```python
class EnhancedKoshaScraper(StandardTableScraper):
    def __init__(self):
        super().__init__()
        # 사이트 특화 설정
        self.base_url = "https://www.kosha.or.kr"
        self.list_url = "https://www.kosha.or.kr/kosha/report/notice.do"
        
    def get_list_url(self, page_num: int) -> str:
        # 설정 주입과 Fallback 패턴
        if self.config and self.config.pagination:
            return super().get_list_url(page_num)
        # Fallback: 사이트 특화 로직
```

### 5.2 중복 체크 시스템
- **자동 중복 검사**: 제목 MD5 해시 기반
- **조기 종료**: 연속 3개 중복 발견 시 자동 중단
- **상태 파일**: `processed_titles_enhancedkosha.json`

### 5.3 에러 처리 및 복원력
- **디버깅 모드**: 상세한 HTML 구조 분석 로그
- **다단계 Fallback**: 본문 추출 실패 시 여러 선택자 시도
- **파일명 복구**: 한글 인코딩 문제 자동 해결

## 6. 재사용 가능한 패턴

### 6.1 JBBA 타입 패턴 (90% 적용 가능)
- 표준 HTML 테이블 구조
- GET 파라미터 페이지네이션
- 직접 링크 방식 첨부파일
- **적용 가능 사이트**: 대부분의 정부기관, 공공기관

### 6.2 상대 URL 처리 패턴
```python
# 재사용 가능한 URL 구성 로직
if href.startswith('?'):
    full_url = f"{self.list_url}{href}"
elif href.startswith('/'):
    full_url = f"{self.base_url}{href}"
else:
    full_url = urljoin(self.base_url, href)
```

## 7. 운영 및 유지보수 고려사항

### 7.1 안정성
- **SSL 검증**: 정상 (verify=True)
- **요청 간격**: 1초 (서버 부하 방지)
- **타임아웃**: 30초
- **재시도**: 3회 (네트워크 오류 시)

### 7.2 확장성
- **설정 주입 준비**: YAML 설정 파일 지원 가능
- **다중 사이트**: Enhanced 베이스 클래스 재사용
- **API 연동**: 표준 인터페이스 제공

### 7.3 모니터링
- **처리 로그**: 구조화된 로깅 시스템
- **성공률 추적**: 자동 검증 및 리포팅
- **파일 무결성**: 크기 및 다운로드 상태 확인

## 8. 특별한 기술적 성취

### 8.1 한글 파일명 100% 성공
- **기존 문제**: `%ED%95%9C%EA%B8%80.hwp` 같은 인코딩 깨짐
- **해결**: RFC 5987 + 다단계 인코딩 복구
- **결과**: 모든 한글 파일명 완벽 처리

### 8.2 대용량 파일 안정 처리
- **스트리밍 다운로드**: 메모리 효율적 처리
- **진행률 표시**: 대용량 파일 다운로드 모니터링
- **중단 복구**: 네트워크 오류 시 재시도

### 8.3 지능형 중복 감지
- **제목 정규화**: 공백, 특수문자 통일 후 해시 비교
- **세션 분리**: 이전 실행과 현재 세션 구분 관리
- **조기 종료**: 불필요한 처리 방지

## 9. 개발자를 위한 팁

### 9.1 디버깅 모드 활용
```python
# 로깅 레벨을 DEBUG로 설정하면 상세한 HTML 구조 분석 가능
logging.basicConfig(level=logging.DEBUG)
```

### 9.2 단일 공고 테스트
```python
# 개발 중 특정 공고만 테스트
scraper = EnhancedKoshaScraper()
response = scraper.get_page('특정_공고_URL')
detail = scraper.parse_detail_page(response.text)
```

### 9.3 첨부파일 검증
```bash
# 한글 파일명 확인
find output/kosha -name "*.pdf" -o -name "*.hwp" | grep -E '[가-힣]'

# 파일 크기 확인  
du -h output/kosha/*/attachments/*
```

## 10. 결론

KOSHA 스크래퍼는 Enhanced 아키텍처의 성공적인 적용 사례로, 표준 HTML 테이블 기반 사이트에 대한 완벽한 솔루션을 제공합니다. 특히 한글 파일명 처리와 대용량 파일 다운로드에서 뛰어난 성능을 보여주며, 향후 유사한 정부기관 사이트 개발 시 직접 활용 가능한 재사용 패턴을 제공합니다.

**핵심 성공 요인**:
1. 상대 URL 처리의 정확한 구현
2. Enhanced 베이스 스크래퍼의 강력한 기능 활용
3. 체계적인 테스트와 검증 프로세스
4. 실제 사용 시나리오를 고려한 안정성 설계