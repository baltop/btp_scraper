#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Export Voucher Enhanced ìŠ¤í¬ë˜í¼ 3í˜ì´ì§€ í…ŒìŠ¤íŠ¸
ìˆ˜ì •ëœ ìŠ¤í¬ë˜í¼ê°€ ì œëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
"""

import os
import shutil
import sys
import time
from enhanced_export_voucher_scraper import EnhancedExportVoucherScraper

def test_enhanced_export_voucher():
    """Enhanced Export Voucher ìŠ¤í¬ë˜í¼ 3í˜ì´ì§€ í…ŒìŠ¤íŠ¸"""
    print("Enhanced Export Voucher ìŠ¤í¬ë˜í¼ 3í˜ì´ì§€ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    output_dir = "output/export_voucher"
    if os.path.exists(output_dir):
        shutil.rmtree(output_dir)
    os.makedirs(output_dir, exist_ok=True)
    
    # ìŠ¤í¬ë˜í¼ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    scraper = EnhancedExportVoucherScraper()
    
    try:
        # 3í˜ì´ì§€ ì²˜ë¦¬
        total_announcements = 0
        total_files = 0
        successful_downloads = 0
        announcements_with_files = 0
        
        for page in range(1, 4):  # 1, 2, 3í˜ì´ì§€
            print(f"\nğŸ” {page}í˜ì´ì§€ ì²˜ë¦¬ ì¤‘...")
            
            # ëª©ë¡ í˜ì´ì§€ URL ìƒì„±
            list_url = scraper.get_list_url(page)
            print(f"ğŸ“‹ ëª©ë¡ URL: {list_url}")
            
            # ëª©ë¡ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
            try:
                response = scraper.session.get(list_url, verify=scraper.verify_ssl, timeout=10)
                if response.status_code != 200:
                    print(f"âŒ í˜ì´ì§€ {page} ì ‘ê·¼ ì‹¤íŒ¨: HTTP {response.status_code}")
                    continue
                    
                # ëª©ë¡ íŒŒì‹±
                announcements = scraper.parse_list_page(response.text)
                print(f"ğŸ“„ {len(announcements)}ê°œ ê³µê³  ë°œê²¬")
                
                if not announcements:
                    print(f"âš ï¸  í˜ì´ì§€ {page}ì— ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # ì¤‘ë³µ ê²€ì‚¬
                new_announcements, early_stop = scraper.filter_new_announcements(announcements)
                print(f"ğŸ†• ì‹ ê·œ ê³µê³ : {len(new_announcements)}ê°œ")
                
                if early_stop:
                    print("ğŸ”„ ì¤‘ë³µ ì„ê³„ê°’ ë„ë‹¬ - ì¡°ê¸° ì¢…ë£Œ")
                    break
                
                # ê° ê³µê³  ì²˜ë¦¬
                page_files = 0
                page_downloads = 0
                page_announcements_with_files = 0
                
                for i, announcement in enumerate(new_announcements, 1):
                    total_announcements += 1
                    announcement_number = (page - 1) * 10 + i
                    
                    print(f"\n  ğŸ“‹ ê³µê³  {announcement_number}: {announcement['title'][:50]}...")
                    
                    # ìƒì„¸ ì²˜ë¦¬
                    try:
                        result = scraper.process_announcement(announcement, announcement_number, output_dir)
                        
                        if result:
                            attachments = result.get('attachments', [])
                            if attachments:
                                page_announcements_with_files += 1
                                page_files += len(attachments)
                                
                                for attachment in attachments:
                                    if attachment.get('download_success', False):
                                        page_downloads += 1
                                        # íŒŒì¼ í¬ê¸° í™•ì¸
                                        local_path = attachment.get('local_path')
                                        if local_path and os.path.exists(local_path):
                                            file_size = os.path.getsize(local_path)
                                            print(f"    âœ… {attachment['name']} ({file_size:,} bytes)")
                                        else:
                                            print(f"    âš ï¸  {attachment['name']} (íŒŒì¼ ì—†ìŒ)")
                                    else:
                                        print(f"    âŒ {attachment['name']} (ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨)")
                            else:
                                print(f"    ğŸ“ ì²¨ë¶€íŒŒì¼ ì—†ìŒ")
                                
                            # ì œëª©ì„ ì²˜ë¦¬ë¨ìœ¼ë¡œ ì¶”ê°€
                            scraper.add_processed_title(announcement['title'])
                            
                        else:
                            print(f"    âŒ ì²˜ë¦¬ ì‹¤íŒ¨")
                    
                    except Exception as e:
                        print(f"    âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    
                    # ê³¼ë¶€í•˜ ë°©ì§€
                    time.sleep(1)
                
                # í˜ì´ì§€ ê²°ê³¼ ìš”ì•½
                print(f"\nğŸ“Š í˜ì´ì§€ {page} ê²°ê³¼:")
                print(f"  - ì²˜ë¦¬ëœ ê³µê³ : {len(new_announcements)}ê°œ")
                print(f"  - ì²¨ë¶€íŒŒì¼ ìˆëŠ” ê³µê³ : {page_announcements_with_files}ê°œ")
                print(f"  - ì´ ì²¨ë¶€íŒŒì¼: {page_files}ê°œ")
                print(f"  - ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {page_downloads}ê°œ")
                
                total_files += page_files
                successful_downloads += page_downloads
                announcements_with_files += page_announcements_with_files
                
            except Exception as e:
                print(f"âŒ í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ì²˜ë¦¬ëœ ì œëª© ì €ì¥
        scraper.save_processed_titles()
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        print(f"\n" + "=" * 60)
        print(f"ğŸ¯ ìµœì¢… ê²°ê³¼ ìš”ì•½:")
        print(f"  - ì´ ì²˜ë¦¬ ê³µê³ : {total_announcements}ê°œ")
        print(f"  - ì²¨ë¶€íŒŒì¼ ìˆëŠ” ê³µê³ : {announcements_with_files}ê°œ")
        print(f"  - ì´ ì²¨ë¶€íŒŒì¼: {total_files}ê°œ")
        print(f"  - ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {successful_downloads}ê°œ")
        
        if total_files > 0:
            success_rate = (successful_downloads / total_files) * 100
            print(f"  - ë‹¤ìš´ë¡œë“œ ì„±ê³µë¥ : {success_rate:.1f}%")
        else:
            print(f"  - ë‹¤ìš´ë¡œë“œ ì„±ê³µë¥ : N/A (ì²¨ë¶€íŒŒì¼ ì—†ìŒ)")
        
        print(f"  - ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        
        # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
        if successful_downloads > 0:
            print(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ! {successful_downloads}ê°œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
            return True
        elif total_files == 0:
            print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì²¨ë¶€íŒŒì¼ì´ ìˆëŠ” ê³µê³  ì—†ìŒ)")
            return True
        else:
            print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨)")
            return False
    
    except Exception as e:
        print(f"\nâŒ ì „ì²´ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_enhanced_export_voucher()
    if success:
        print("\nâœ… Export Voucher Enhanced í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        sys.exit(0)
    else:
        print("\nğŸ’¥ Export Voucher Enhanced í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
        sys.exit(1)